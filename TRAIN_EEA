python run_custom_seq_labeling.py \
  --task_name=eea \
  --do_lower_case=true \
  --do_train=true \
  --do_eval=false \
  --do_predict=false \
  --save_for_serving=false \
  --data_dir=./data/eea \
  --vocab_file=./model_data/uncased_L-12_H-768_A-12/vocab.txt \
  --bert_config_file=./model_data/uncased_L-12_H-768_A-12/bert_config.json \
  --init_checkpoint=./model_data/uncased_L-12_H-768_A-12/bert_model.ckpt \
  --max_seq_length=128 \
  --train_batch_size=32 \
  --learning_rate=5e-5 \
  --num_train_epochs=20 \
  --use_gpu=true \
  --num_gpu_cores=1 \
  --use_fp16=true \
  --output_dir=./eea_direct
